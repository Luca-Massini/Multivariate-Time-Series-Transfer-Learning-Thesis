{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "InsectWingbeat .ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IBt0GxTU50ff",
    "outputId": "a6594382-62f7-456e-e491-6a79e5838de7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sktime\n",
      "  Downloading sktime-0.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.2 MB 5.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: statsmodels<=0.12.1 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.10.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
      "Collecting statsmodels>=0.12.1\n",
      "  Downloading statsmodels-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 9.8 MB 38.9 MB/s \n",
      "\u001B[?25hCollecting numba>=0.53\n",
      "  Downloading numba-0.55.0-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 45.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.37.1)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting numpy<=1.19.3\n",
      "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 14.9 MB 45.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.0.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.13->sktime) (1.13.3)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 34.5 MB 8.1 kB/s \n",
      "\u001B[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53->sktime) (57.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.4.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\n",
      "Installing collected packages: numpy, llvmlite, statsmodels, numba, deprecated, sktime\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.34.0\n",
      "    Uninstalling llvmlite-0.34.0:\n",
      "      Successfully uninstalled llvmlite-0.34.0\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.10.2\n",
      "    Uninstalling statsmodels-0.10.2:\n",
      "      Successfully uninstalled statsmodels-0.10.2\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.51.2\n",
      "    Uninstalling numba-0.51.2:\n",
      "      Successfully uninstalled numba-0.51.2\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\n",
      "sktime 0.9.0 requires statsmodels<=0.12.1, but you have statsmodels 0.13.1 which is incompatible.\u001B[0m\n",
      "Successfully installed deprecated-1.2.13 llvmlite-0.38.0 numba-0.55.0 numpy-1.19.3 sktime-0.9.0 statsmodels-0.13.1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "'''\n",
    "pip install sktime\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "!git clone https://github_access_token@github.com/Luca-Massini/Time-Series-Classification.git\n",
    "'''"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A_l7bnv6T8q",
    "outputId": "c7128108-529c-43d3-ad48-82436dfa04cd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Time-Series-Classification'...\n",
      "remote: Enumerating objects: 1117, done.\u001B[K\n",
      "remote: Counting objects: 100% (1117/1117), done.\u001B[K\n",
      "remote: Compressing objects: 100% (797/797), done.\u001B[K\n",
      "remote: Total 1117 (delta 795), reused 568 (delta 313), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (1117/1117), 236.86 KiB | 6.58 MiB/s, done.\n",
      "Resolving deltas: 100% (795/795), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "'''"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_6foewr6WZV",
    "outputId": "88d4be5a-8af1-4fb9-d03a-7f5b7bb8048d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "id": "MwDSjr_V6ba5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cd Time-Series-Classification/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vruTRQY57Hbs",
    "outputId": "ba7205a7-2e8f-4f74-e446-6be4f08dc863"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/Time-Series-Classification\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from runMultivariate2018DatasetChannel import runMultivariate2018DatasetChannel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "0DpcqGaf6sk5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "datasetName = \"InsectWingbeat\"\n",
    "normalization = True\n",
    "data_location = \"../Transformer/Data/Multivariate_ts\"\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Hyper-parameters\n",
    "filter_size_autoEncoder=3\n",
    "n_layers_autoEncoder=1\n",
    "convolutions_per_layer_autoEncoder=1\n",
    "n_filters_index_autoEncoder=2\n",
    "reducing_length_factor_autoEncoder=2\n",
    "embedding_size=128\n",
    "feedForward_dimension=256\n",
    "nHeads=16\n",
    "dropout=0.1\n",
    "n_encoders=3\n",
    "\n",
    "experiments_runner = runMultivariate2018DatasetChannel(filter_size_autoEncoder = filter_size_autoEncoder,\n",
    "                                                       n_layers_autoEncoder = n_layers_autoEncoder,\n",
    "                                                       convolutions_per_layer_autoEncoder = convolutions_per_layer_autoEncoder,\n",
    "                                                       n_filters_index_autoEncoder = n_filters_index_autoEncoder,\n",
    "                                                       reducing_length_factor_autoEncoder = reducing_length_factor_autoEncoder,\n",
    "                                                       embedding_size = embedding_size,\n",
    "                                                       feedForward_dimension = feedForward_dimension,\n",
    "                                                       nHeads = nHeads,\n",
    "                                                       dropout = dropout,\n",
    "                                                       n_encoders = n_encoders,\n",
    "                                                       device = device,\n",
    "                                                       dataSetName = datasetName,\n",
    "                                                       dataLocation = data_location,\n",
    "                                                       normalization = normalization)\n",
    "experiments_runner.run(n_exp=5,\n",
    "                       epochs=3500,\n",
    "                       batch_size=64,\n",
    "                       learning_rate=1e-4,\n",
    "                       ReduceLROnPlateau=False,\n",
    "                       optimizer='RAdam',\n",
    "                       factor=0.1,\n",
    "                       min_lr=1e-18,\n",
    "                       patience=10,\n",
    "                       channel_sizes=[3, 5, 10],\n",
    "                       file_to_write_path=\"../Transformer/Data\")"
   ],
   "metadata": {
    "id": "v7B7OWVr7Jec"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}