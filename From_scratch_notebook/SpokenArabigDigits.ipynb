{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwDSjr_V6ba5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DpcqGaf6sk5"
   },
   "outputs": [],
   "source": [
    "from runMultivariate2018DatasetChannel import runMultivariate2018DatasetChannel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7B7OWVr7Jec"
   },
   "outputs": [],
   "source": [
    "datasetName = \"SpokenArabicDigits\"\n",
    "normalization = True\n",
    "data_location = \"../Transformer/Data/Multivariate_ts\"\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Hyper-parameters\n",
    "filter_size_autoEncoder=3\n",
    "n_layers_autoEncoder=1\n",
    "convolutions_per_layer_autoEncoder=1\n",
    "n_filters_index_autoEncoder=2\n",
    "reducing_length_factor_autoEncoder=2\n",
    "embedding_size=64\n",
    "feedForward_dimension=256\n",
    "nHeads=8\n",
    "dropout=0.1\n",
    "n_encoders=3\n",
    "\n",
    "experiments_runner = runMultivariate2018DatasetChannel(filter_size_autoEncoder = filter_size_autoEncoder,\n",
    "                                                       n_layers_autoEncoder = n_layers_autoEncoder,\n",
    "                                                       convolutions_per_layer_autoEncoder = convolutions_per_layer_autoEncoder,\n",
    "                                                       n_filters_index_autoEncoder = n_filters_index_autoEncoder,\n",
    "                                                       reducing_length_factor_autoEncoder = reducing_length_factor_autoEncoder,\n",
    "                                                       embedding_size = embedding_size,\n",
    "                                                       feedForward_dimension = feedForward_dimension,\n",
    "                                                       nHeads = nHeads,\n",
    "                                                       dropout = dropout,\n",
    "                                                       n_encoders = n_encoders,\n",
    "                                                       device = device,\n",
    "                                                       dataSetName = datasetName,\n",
    "                                                       dataLocation = data_location,\n",
    "                                                       normalization = normalization)\n",
    "experiments_runner.run(n_exp=5,\n",
    "                       epochs=3500,\n",
    "                       batch_size=64,\n",
    "                       learning_rate=1e-4,\n",
    "                       ReduceLROnPlateau=False,\n",
    "                       optimizer='RAdam',\n",
    "                       factor=0.1,\n",
    "                       min_lr=1e-18,\n",
    "                       patience=10,\n",
    "                       channel_sizes=[3, 5, 10],\n",
    "                       file_to_write_path=\"../Transformer/Data\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SpokenArabigDigits.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
